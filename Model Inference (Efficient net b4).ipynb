{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch from sklearn.metrics \nimport confusion_matrix, precision_score, recall_score, f1_score, accuracy_score \nimport matplotlib.pyplot as plt \nimport seaborn as sns \nimport numpy as np from torchvision \nimport datasets, transforms, models from torchvision.models \nimport efficientnet_b4, EfficientNet_B4_Weights \nimport torch.nn as nn \n# Hyperparameters and paths (modify as necessary) \ndropout_rate = 0.6 batch_size = 32 num_classes = 2 # Modify based on your problem \ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n# Transforms for test dataset (same as validation) \nval_transforms = transforms.Compose([ transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ]) \n# Load the test dataset \ntest_dataset = datasets.ImageFolder(root='/kaggle/input/audiospec/output_spectrograms/output_spectrograms', transform=val_transforms) \ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True) \n# Load EfficientNet-B4 model \nmodel = efficientnet_b4(weights=EfficientNet_B4_Weights.DEFAULT) num_features = model.classifier[1].in_features model.classifier = nn.Sequential( nn.Dropout(dropout_rate), nn.Linear(num_features, num_classes)\n) \n# Load the saved model weights \nmodel_path = '/kaggle/input/effi_thursday/pytorch/default/1/efficientnet_b4_model_weights.pth' # Update this with the actual path \nmodel.load_state_dict(torch.load(model_path)) # Load the model weights \nmodel.to(device) # Send the model to the appropriate device (GPU or CPU) \n# Set the model to evaluation mode \nmodel.eval() # Function to evaluate on the test set and compute metrics \ndef evaluate_on_test_set(model, test_loader): all_labels = [] all_predictions = [] with torch.no_grad(): # Disable gradient calculation for inference for images, \nlabels in test_loader: images, labels = images.to(device), labels.to(device) outputs = model(images) _, predicted = torch.max(outputs.data, 1) # Get predictions\n# Store true labels and predictions \nall_labels.extend(labels.cpu().numpy()) all_predictions.extend(predicted.cpu().numpy()) \n# Calculate precision, recall, F1 score, and accuracy \nprecision = precision_score(all_labels, all_predictions, average='macro') \nrecall = recall_score(all_labels, all_predictions, average='macro') \nf1 = f1_score(all_labels, all_predictions, average='macro') \naccuracy = accuracy_score(all_labels, all_predictions) \nprint(f'Precision (Macro): {precision:.4f}') print(f'Recall (Macro): {recall:.4f}') print(f'F1 Score (Macro): {f1:.4f}') print(f'Accuracy: {accuracy:.4f}') return all_labels, all_predictions \n# Function to plot confusion matrix \ndef plot_confusion_matrix(all_labels, all_predictions, class_names):\ncm = confusion_matrix(all_labels, all_predictions) plt.figure(figsize=(8, 6)) sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names) plt.xlabel('Predicted') plt.ylabel('Actual') plt.title('Confusion Matrix') plt.show() # Run the inference on the test set \nall_test_labels, all_test_predictions = evaluate_on_test_set(model, test_loader) # Plot confusion matrix \nplot_confusion_matrix(all_test_labels, all_test_predictions, class_names=test_dataset.classes)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}