{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms, models\nfrom torchvision.models import ResNet101_Weights\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom tqdm import tqdm # Progress bar\n# Hyperparameters\nbatch_size = 16\nlearning_rate = 0.0001\nnum_epochs = 25\nweight_decay = 1e-4 # L2 regularization\ndropout_rate = 0.6\nnum_classes = 2 # For your 'fake' and 'real' classes\npatience = 5 # Number of epochs to wait for improvement before stopping\n# Data augmentation and normalization\ntrain_transforms = transforms.Compose([\ntransforms.RandomResizedCrop(224),\ntransforms.RandomHorizontalFlip(),\ntransforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\ntransforms.RandomRotation(10),\ntransforms.ToTensor(),\ntransforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\nval_transforms = transforms.Compose([\ntransforms.Resize(256),\ntransforms.CenterCrop(224),\ntransforms.ToTensor(),\ntransforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n# Load datasets\ntrain_dataset = datasets.ImageFolder(root='/kaggle/input/audiospec/output_spectrograms_training/output_spectrograms_training', transform=train_transforms)\nval_dataset = datasets.ImageFolder(root='/kaggle/input/audiospec/output_spectrograms_training/output_spectrograms_training', transform=val_transforms)\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n# Load a pre-trained ResNet101 model\nmodel = models.resnet101(weights=ResNet101_Weights.DEFAULT)\nnum_features = model.fc.in_features\nmodel.fc = nn.Sequential(\nnn.Dropout(dropout_rate),\nnn.Linear(num_features, num_classes)\n)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n# Loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n# Early Stopping class\nclass EarlyStopping:\ndef __init__(self, patience=patience, verbose=False):\nself.patience = patience\nself.verbose = verbose\nself.counter = 0\nself.best_loss = float('inf')\nself.early_stop = False\ndef __call__(self, val_loss):\nif val_loss < self.best_loss:\nself.best_loss = val_loss\nself.counter = 0\nelse:\nself.counter += 1\nif self.counter >= self.patience:\nself.early_stop = True\nif self.verbose:\nprint(f'Early stopping triggered after {self.patience} epochs without improvement.')\n# Track metrics\ntrain_losses, val_losses = [], []\ntrain_accuracies, val_accuracies = [], []\n# Define a learning rate scheduler\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n# Training and validation loop with progress bar\ndef train_and_evaluate(model, criterion, optimizer, num_epochs):\nearly_stopping = EarlyStopping(patience=patience, verbose=True)\nfor epoch in range(num_epochs):\nmodel.train()\nrunning_loss = 0.0\ncorrect = 0\ntotal = 0\n# Training loop with progress bar\ntrain_loader_progress = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)\nfor images, labels in train_loader_progress:\nimages, labels = images.to(device), labels.to(device)\noutputs = model(images)\nloss = criterion(outputs, labels)\noptimizer.zero_grad()\nloss.backward()\noptimizer.step()\nrunning_loss += loss.item()\n_, predicted = torch.max(outputs.data, 1)\ntotal += labels.size(0)\ncorrect += (predicted == labels).sum().item()\ntrain_accuracy = 100 * correct / total\ntrain_loss = running_loss / len(train_loader)\ntrain_losses.append(train_loss)\ntrain_accuracies.append(train_accuracy)\n# Validation loop\nmodel.eval()\nval_loss = 0.0\nval_correct = 0\nval_total = 0\nall_labels = []\nall_predictions = []\nwith torch.no_grad():\nfor images, labels in val_loader:\nimages, labels = images.to(device), labels.to(device)\noutputs = model(images)\nloss = criterion(outputs, labels)\nval_loss += loss.item()\n_, predicted = torch.max(outputs.data, 1)\nval_total += labels.size(0)\nval_correct += (predicted == labels).sum().item()\nall_labels.extend(labels.cpu().numpy())\nall_predictions.extend(predicted.cpu().numpy())\nval_accuracy = 100 * val_correct / val_total\nval_loss = val_loss / len(val_loader)\nval_losses.append(val_loss)\nval_accuracies.append(val_accuracy)\n# Calculate precision, recall, and F1 score\nprecision = precision_score(all_labels, all_predictions, average='macro')\nrecall = recall_score(all_labels, all_predictions, average='macro')\nf1 = f1_score(all_labels, all_predictions, average='macro')\n# Step the scheduler\nscheduler.step()\nprint(f'Epoch [{epoch+1}/{num_epochs}], '\nf'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, '\nf'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%, '\nf'Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n# Check for early stopping\nearly_stopping(val_loss)\nif early_stopping.early_stop:\nprint(\"Early stopping triggered.\")\nbreak\n# Save the model weights\ntorch.save(model.state_dict(), 'resnet101_model_weights.pth')\n# Run the training and validation\ntrain_and_evaluate(model, criterion, optimizer, num_epochs)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}